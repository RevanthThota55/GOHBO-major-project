{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest X-Ray Pneumonia Detection - Training on Kaggle\n",
    "\n",
    "**Task**: Binary classification (NORMAL vs PNEUMONIA)\n",
    "\n",
    "**Before running, make sure you have:**\n",
    "1. GPU enabled: Settings -> Accelerator -> GPU P100 or T4\n",
    "2. Added dataset: + Add Input -> Search `chest-xray-pneumonia` by Paul Mooney\n",
    "3. Added your code: + Add Input -> Upload `project_for_colab.zip`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Cell 1: Check GPU and find datasets\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GPU CHECK\")\n",
    "print(\"=\" * 50)\n",
    "!nvidia-smi -L 2>/dev/null || echo \"No GPU found\"\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DATASET SEARCH\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show what kaggle has in /kaggle/input\n",
    "print(\"\\nAll files in /kaggle/input:\")\n",
    "!find /kaggle/input -maxdepth 5 -type f | head -30\n",
    "\n",
    "print(\"\\nAll directories in /kaggle/input:\")\n",
    "!find /kaggle/input -maxdepth 5 -type d | head -30\n",
    "\n",
    "# Search for project zip\n",
    "project_zip_path = None\n",
    "chest_xray_data_path = None\n",
    "\n",
    "for root, dirs, files in os.walk('/kaggle/input'):\n",
    "    for f in files:\n",
    "        if f.endswith('.zip'):\n",
    "            project_zip_path = os.path.join(root, f)\n",
    "    if 'train.py' in files and 'config.py' in files:\n",
    "        if project_zip_path is None:\n",
    "            project_zip_path = root\n",
    "    if 'train' in dirs and 'test' in dirs:\n",
    "        train_path = os.path.join(root, 'train')\n",
    "        if os.path.isdir(train_path):\n",
    "            contents = os.listdir(train_path)\n",
    "            if 'NORMAL' in contents and 'PNEUMONIA' in contents:\n",
    "                if chest_xray_data_path is None:\n",
    "                    chest_xray_data_path = root\n",
    "\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(f\"Project zip:     {project_zip_path or 'NOT FOUND'}\")\n",
    "print(f\"Chest xray data: {chest_xray_data_path or 'NOT FOUND'}\")\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "if not project_zip_path:\n",
    "    print(\"\\n>>> ADD YOUR PROJECT: + Add Input -> Upload project_for_colab.zip\")\n",
    "if not chest_xray_data_path:\n",
    "    print(\"\\n>>> ADD DATASET: + Add Input -> Search 'chest-xray-pneumonia'\")\n",
    "if project_zip_path and chest_xray_data_path:\n",
    "    print(\"\\n[OK] Everything found! Continue to Cell 2.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Cell 2: Extract project and write hyperparameters\n",
    "import os, json, shutil\n",
    "\n",
    "project_dir = '/kaggle/working/medical-image-classification'\n",
    "\n",
    "if os.path.exists(project_dir):\n",
    "    shutil.rmtree(project_dir)\n",
    "\n",
    "if project_zip_path is None:\n",
    "    raise Exception(\"No project found! Go back to Cell 1 and add your project dataset.\")\n",
    "\n",
    "if project_zip_path.endswith('.zip'):\n",
    "    os.makedirs(project_dir, exist_ok=True)\n",
    "    os.system(f'unzip -q \"{project_zip_path}\" -d \"{project_dir}\"')\n",
    "    print(f\"[OK] Extracted: {project_zip_path}\")\n",
    "else:\n",
    "    shutil.copytree(project_zip_path, project_dir)\n",
    "    print(f\"[OK] Copied: {project_zip_path}\")\n",
    "\n",
    "%cd {project_dir}\n",
    "\n",
    "# Write chest X-ray hyperparameters\n",
    "params = {\n",
    "    \"best_hyperparameters\": {\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 50\n",
    "    },\n",
    "    \"optimization_summary\": {\n",
    "        \"method\": \"transferred_from_brain_tumor\",\n",
    "        \"dataset\": \"chest_xray\",\n",
    "        \"classes\": 2\n",
    "    },\n",
    "    \"dataset_info\": {\n",
    "        \"name\": \"Chest X-Ray Pneumonia Detection\",\n",
    "        \"classes\": [\"NORMAL\", \"PNEUMONIA\"],\n",
    "        \"num_classes\": 2\n",
    "    }\n",
    "}\n",
    "os.makedirs('results/phase1', exist_ok=True)\n",
    "with open('results/phase1/best_hyperparameters.json', 'w') as f:\n",
    "    json.dump(params, f, indent=2)\n",
    "\n",
    "print(\"[OK] Hyperparameters written!\")\n",
    "!ls"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Cell 3: Install dependencies\n",
    "!pip install -q albumentations scikit-image 2>/dev/null\n",
    "import torch, torchvision, sklearn, PIL\n",
    "print(f\"PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}\")\n",
    "print(\"[OK] Dependencies ready!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Cell 4: Link chest xray dataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if chest_xray_data_path is None:\n",
    "    raise Exception(\"No chest xray dataset found! Go back to Cell 1 and add it.\")\n",
    "\n",
    "print(f\"Dataset source: {chest_xray_data_path}\")\n",
    "os.makedirs('data/chest_xray', exist_ok=True)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    link = f'data/chest_xray/{split}'\n",
    "    source = os.path.join(chest_xray_data_path, split)\n",
    "    if os.path.islink(link) or os.path.exists(link):\n",
    "        os.remove(link)\n",
    "    if os.path.exists(source):\n",
    "        os.symlink(source, link)\n",
    "        print(f\"  {split}: linked\")\n",
    "    else:\n",
    "        print(f\"  {split}: not found (skipping)\")\n",
    "\n",
    "def count_imgs(d):\n",
    "    return sum(len(list(Path(d).rglob(e))) for e in ['*.jpeg','*.jpg','*.png'])\n",
    "\n",
    "print(f\"\\nImage counts:\")\n",
    "for s in ['train','val','test']:\n",
    "    p = f'data/chest_xray/{s}'\n",
    "    if os.path.exists(p):\n",
    "        print(f\"  {s}: {count_imgs(p)}\")\n",
    "\n",
    "print(f\"\\nClasses in train:\")\n",
    "for c in ['NORMAL','PNEUMONIA']:\n",
    "    p = f'data/chest_xray/train/{c}'\n",
    "    if os.path.exists(p):\n",
    "        print(f\"  {c}: {count_imgs(p)}\")\n",
    "\n",
    "print(\"\\n[OK] Dataset ready!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Cell 5: Verify config\n",
    "!python -c \"from config import get_config; c = get_config('chest_xray'); print('Config:', c['dataset']['name'], '| Classes:', c['dataset']['num_classes'])\"\n",
    "!python -c \"from src.datasets.chest_xray import ChestXRayDataset; print('Dataset loader: OK')\"\n",
    "print(\"\\nHyperparameters:\")\n",
    "!cat results/phase1/best_hyperparameters.json\n",
    "print(\"\\n[OK] Ready to train!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Cell 6: TRAIN!\n",
    "print(\"=\" * 60)\n",
    "print(\"  TRAINING: Chest X-Ray | ResNet-18 | 50 epochs\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "!python train.py --dataset chest_xray --use_optimized --device cuda\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"  TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Cell 7: Results\n",
    "import json, os\n",
    "\n",
    "!ls -lh models/checkpoints/\n",
    "\n",
    "if os.path.exists('results/phase1/training_history.json'):\n",
    "    with open('results/phase1/training_history.json') as f:\n",
    "        h = json.load(f)\n",
    "    print(f\"\\nTrain Acc:  {h['train_acc'][-1]:.2f}%\")\n",
    "    print(f\"Val Acc:    {h['val_acc'][-1]:.2f}%\")\n",
    "    print(f\"Epochs:     {len(h['train_acc'])}\")\n",
    "    print(f\"Best Val:   {max(h['val_acc']):.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    "# Cell 8: Save for download\n",
    "import shutil\n",
    "\n",
    "for f in ['models/checkpoints/best_model.pth', 'results/phase1/training_history.json', 'results/training_results_chest_xray.json']:\n",
    "    if os.path.exists(f):\n",
    "        shutil.copy2(f, '/kaggle/working/')\n",
    "        print(f\"[OK] {os.path.basename(f)}\")\n",
    "\n",
    "print(\"\\nFiles ready:\")\n",
    "!ls -lh /kaggle/working/*.pth /kaggle/working/*.json 2>/dev/null\n",
    "print(\"\\nClick 'Save Version' -> 'Save & Run All' -> then download from Output tab\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
