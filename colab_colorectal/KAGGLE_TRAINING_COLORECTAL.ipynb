{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorectal Histology Classification - Training on Kaggle\n",
    "\n",
    "**Task**: 8-class tissue type classification from histopathology images\n",
    "\n",
    "**Before running, make sure you have:**\n",
    "1. GPU enabled: Settings -> Accelerator -> GPU P100 or T4\n",
    "2. Added dataset: + Add Input -> Search `colorectal-histology-mnist` by Kevin Mader\n",
    "3. Added your code: + Add Input -> Upload `project_for_colab.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Check GPU and find datasets\nimport torch\nimport os\n\nprint('=' * 50)\nprint('GPU CHECK')\nprint('=' * 50)\n!nvidia-smi -L 2>/dev/null || echo 'No GPU found'\nprint(f'PyTorch: {torch.__version__}')\nprint(f'CUDA: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n\nprint('\\n' + '=' * 50)\nprint('DATASET SEARCH')\nprint('=' * 50)\n\n# Show what kaggle has in /kaggle/input\nprint('\\nAll directories in /kaggle/input:')\n!find /kaggle/input -maxdepth 5 -type d | head -40\n\n# Search for project (zip OR extracted folder) and colorectal data\nproject_zip_path = None\nproject_folder_path = None\ncolorectal_data_path = None\n\nfor root, dirs, files in os.walk('/kaggle/input'):\n    # Find project zip file\n    for f in files:\n        if f.endswith('.zip') and 'project' in f.lower():\n            project_zip_path = os.path.join(root, f)\n    # Find extracted project folder (Kaggle auto-extracts zips)\n    if 'train.py' in files and 'config.py' in files:\n        project_folder_path = root\n    # Find colorectal data (look for the numbered class folders)\n    if '01_TUMOR' in dirs and '08_EMPTY' in dirs:\n        colorectal_data_path = root\n\n# Prefer extracted folder over zip\nproject_path = project_folder_path or project_zip_path\nproject_type = 'folder' if project_folder_path else ('zip' if project_zip_path else None)\n\nprint(f'\\n{\"=\" * 50}')\nprint(f'Project:          {project_path or \"NOT FOUND\"} ({project_type or \"N/A\"})')\nprint(f'Colorectal data:  {colorectal_data_path or \"NOT FOUND\"}')\nprint(f'{\"=\" * 50}')\n\nif not project_path:\n    print('\\n>>> ADD YOUR PROJECT: + Add Input -> Upload project_for_colab.zip')\nif not colorectal_data_path:\n    print('\\n>>> ADD DATASET: + Add Input -> Search \"colorectal-histology-mnist\"')\nif project_path and colorectal_data_path:\n    print('\\n[OK] Everything found! Continue to Cell 2.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Extract/copy project and write hyperparameters\nimport os, json, shutil\n\nproject_dir = '/kaggle/working/medical-image-classification'\n\nif os.path.exists(project_dir):\n    shutil.rmtree(project_dir)\n\nif project_path is None:\n    raise Exception('No project found! Go back to Cell 1 and add your project dataset.')\n\nif project_type == 'zip':\n    os.makedirs(project_dir, exist_ok=True)\n    os.system(f'unzip -q \"{project_path}\" -d \"{project_dir}\"')\n    print(f'[OK] Extracted zip: {project_path}')\nelse:\n    # Kaggle auto-extracted the zip - copy the folder\n    shutil.copytree(project_path, project_dir)\n    print(f'[OK] Copied folder: {project_path}')\n\n%cd {project_dir}\n\n# Write colorectal hyperparameters\nparams = {\n    'best_hyperparameters': {\n        'learning_rate': 0.001,\n        'batch_size': 32,\n        'epochs': 70\n    },\n    'optimization_summary': {\n        'method': 'transferred_from_brain_tumor',\n        'note': '8-class classification needs more epochs than binary',\n        'dataset': 'colorectal',\n        'classes': 8\n    },\n    'dataset_info': {\n        'name': 'Colorectal Cancer Histopathology',\n        'classes': ['TUMOR', 'STROMA', 'COMPLEX', 'LYMPHO', 'DEBRIS', 'MUCOSA', 'ADIPOSE', 'EMPTY'],\n        'num_classes': 8\n    }\n}\nos.makedirs('results/phase1', exist_ok=True)\nwith open('results/phase1/best_hyperparameters.json', 'w') as f:\n    json.dump(params, f, indent=2)\n\nprint('[OK] Hyperparameters written!')\nprint('\\nProject files:')\n!ls"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Install dependencies\n",
    "!pip install -q albumentations scikit-image 2>/dev/null\n",
    "import torch, torchvision, sklearn, PIL\n",
    "print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')\n",
    "print('[OK] Dependencies ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Split dataset into train/val/test and rename folders\n",
    "import os, shutil, random\n",
    "from pathlib import Path\n",
    "\n",
    "if colorectal_data_path is None:\n",
    "    raise Exception('No colorectal dataset found! Go back to Cell 1 and add it.')\n",
    "\n",
    "print(f'Dataset source: {colorectal_data_path}')\n",
    "\n",
    "# Mapping from Kather folder names to our class names\n",
    "FOLDER_TO_CLASS = {\n",
    "    '01_TUMOR': 'TUMOR',\n",
    "    '02_STROMA': 'STROMA',\n",
    "    '03_COMPLEX': 'COMPLEX',\n",
    "    '04_LYMPHO': 'LYMPHO',\n",
    "    '05_DEBRIS': 'DEBRIS',\n",
    "    '06_MUCOSA': 'MUCOSA',\n",
    "    '07_ADIPOSE': 'ADIPOSE',\n",
    "    '08_EMPTY': 'EMPTY'\n",
    "}\n",
    "\n",
    "# Split ratios\n",
    "TRAIN_RATIO = 0.80\n",
    "VAL_RATIO = 0.10\n",
    "TEST_RATIO = 0.10\n",
    "\n",
    "random.seed(42)  # Reproducible splits\n",
    "\n",
    "data_dir = Path('data/colorectal')\n",
    "\n",
    "# Clean up any previous setup\n",
    "if data_dir.exists():\n",
    "    shutil.rmtree(data_dir)\n",
    "\n",
    "# Create split directories\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for cls in FOLDER_TO_CLASS.values():\n",
    "        (data_dir / split / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'\\nSplitting dataset ({TRAIN_RATIO:.0%} train / {VAL_RATIO:.0%} val / {TEST_RATIO:.0%} test):')\n",
    "print(f'{\"=\"*60}')\n",
    "\n",
    "total_train = total_val = total_test = 0\n",
    "\n",
    "for folder_name, class_name in FOLDER_TO_CLASS.items():\n",
    "    src_dir = Path(colorectal_data_path) / folder_name\n",
    "    if not src_dir.exists():\n",
    "        print(f'  [WARN] {folder_name} not found, skipping')\n",
    "        continue\n",
    "    \n",
    "    # Get all image files\n",
    "    images = list(src_dir.glob('*.tif')) + list(src_dir.glob('*.jpg')) + list(src_dir.glob('*.png'))\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    n = len(images)\n",
    "    n_train = int(n * TRAIN_RATIO)\n",
    "    n_val = int(n * VAL_RATIO)\n",
    "    n_test = n - n_train - n_val\n",
    "    \n",
    "    train_imgs = images[:n_train]\n",
    "    val_imgs = images[n_train:n_train + n_val]\n",
    "    test_imgs = images[n_train + n_val:]\n",
    "    \n",
    "    # Copy files (symlinks don't work well on Kaggle for nested paths)\n",
    "    for img in train_imgs:\n",
    "        shutil.copy2(str(img), str(data_dir / 'train' / class_name / img.name))\n",
    "    for img in val_imgs:\n",
    "        shutil.copy2(str(img), str(data_dir / 'val' / class_name / img.name))\n",
    "    for img in test_imgs:\n",
    "        shutil.copy2(str(img), str(data_dir / 'test' / class_name / img.name))\n",
    "    \n",
    "    total_train += n_train\n",
    "    total_val += n_val\n",
    "    total_test += n_test\n",
    "    \n",
    "    print(f'  {class_name:8s}: {n:4d} total -> {n_train:4d} train / {n_val:3d} val / {n_test:3d} test')\n",
    "\n",
    "print(f'{\"=\"*60}')\n",
    "print(f'  TOTAL:   {total_train + total_val + total_test:4d} total -> {total_train:4d} train / {total_val:3d} val / {total_test:3d} test')\n",
    "print(f'\\n[OK] Dataset split and ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Verify config and dataset loader\n",
    "!python -c \"from config import get_config; c = get_config('colorectal'); print('Config:', c['dataset']['name'], '| Classes:', c['dataset']['num_classes'])\"\n",
    "!python -c \"from src.datasets.colorectal import ColorectalDataset; print('Dataset loader: OK')\"\n",
    "print('\\nHyperparameters:')\n",
    "!cat results/phase1/best_hyperparameters.json\n",
    "print('\\n[OK] Ready to train!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: TRAIN!\n",
    "print('=' * 60)\n",
    "print('  TRAINING: Colorectal Histology | ResNet-18 | 70 epochs')\n",
    "print('  8 classes: TUMOR, STROMA, COMPLEX, LYMPHO,')\n",
    "print('             DEBRIS, MUCOSA, ADIPOSE, EMPTY')\n",
    "print('=' * 60 + '\\n')\n",
    "\n",
    "!python train.py --dataset colorectal --use_optimized --device cuda\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('  TRAINING COMPLETE!')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Results\n",
    "import json, os\n",
    "\n",
    "!ls -lh models/checkpoints/\n",
    "\n",
    "if os.path.exists('results/phase1/training_history.json'):\n",
    "    with open('results/phase1/training_history.json') as f:\n",
    "        h = json.load(f)\n",
    "    print(f'\\nTrain Acc:  {h[\"train_acc\"][-1]:.2f}%')\n",
    "    print(f'Val Acc:    {h[\"val_acc\"][-1]:.2f}%')\n",
    "    print(f'Epochs:     {len(h[\"train_acc\"])}')\n",
    "    print(f'Best Val:   {max(h[\"val_acc\"]):.2f}%')\n",
    "else:\n",
    "    print('\\nNo training history found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Save for download\n",
    "import shutil\n",
    "\n",
    "for f in ['models/checkpoints/best_model.pth', 'results/phase1/training_history.json', 'results/training_results_colorectal.json']:\n",
    "    if os.path.exists(f):\n",
    "        shutil.copy2(f, '/kaggle/working/')\n",
    "        print(f'[OK] {os.path.basename(f)}')\n",
    "\n",
    "print('\\nFiles ready:')\n",
    "!ls -lh /kaggle/working/*.pth /kaggle/working/*.json 2>/dev/null\n",
    "print('\\nClick \"Save Version\" -> \"Save & Run All\" -> then download from Output tab')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}